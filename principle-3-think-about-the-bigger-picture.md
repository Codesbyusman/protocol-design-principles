# Principle 3: Think about the bigger picture

No protocol exists in isolation. Protocols designed today may have unintended consequences or be influenced in unexpected ways, from security concerns directly related to the protocol (such as where cryptographic keys are stored) through implications for software and devices (such as side-channel attacks) to impacts on the wider internet ecosystem (such as market diversity, introduction of DDoS amplification attacks or other protocols). Users need more than just a secure protocol, they need a secure and robust ecosystem, now and in the future – considering the impacts of a protocol design is vital in achieving that.

## 3.1 Encourage diversity

Service diversity should be encouraged because it allows users to make the best choice to support their use cases and privacy. A sufficiently broad market of services would give commercial success to participants and allow new profitable entrants to the market, while providing good user choice. However, if protocols are designed in such a way that constrains the ability for services to succeed in a well-functioning market, then this limits user choice.

Design decisions, including the mechanism and architecture chosen, can contribute to a lack of provider diversity. For example, if a new protocol is hard to upgrade to or implement, then only larger stakeholders will initially have the ability to do so, enabling market capture at an early stage and potentially leading to single points of failure.

Market dominance effects, resulting in concentration, and possible commercialisation, of users’ personal data are important considerations for wider society and user privacy. If a service has only a handful of providers then user choice is restricted, making it more likely that users are forced into making undesirable privacy-critical decisions – for example using a service provider they would not otherwise trust with their personal data.

Lack of service diversity also increases the likelihood of more widely shared vulnerabilities, which give attackers a better chance of disruption or compromise on a large scale. Attackers' motivations may also increase correspondingly. Diversity of service provision can therefore increase the security and resilience of the whole ecosystem.

## 3.2 Consider secure implementation

A protocol may use cryptographically proven methods, but traditional communications security and cryptanalytic attacks are just some of the threats that protocols may face. Further threats include side-channel attacks (where an attacker observes information about an implementation of a protocol which can be used to derive secret information) and social engineering attacks (such as phishing, where a user is tricked into revealing private information to an attacker). Through due consideration of the endpoint environment that the protocol operates in, it is often possible for protocol designers to not only make secure implementation easier, but also to foresee implementation choices that enable alternative attacks and warn against them.

Formal verification of protocol security is growing in popularity, especially for protocols that will be widely used, and hence have their security highly relied upon and regularly challenged. Conducting this sort of analysis on the state machine underlying the protocol is not cheap or easy but can be desirable for some protocols. Designing the protocol in such a way to enable this analysis (see 2.1) or making it part of the design process, is likely to be increasingly common in the future.

Protocol design decisions can also help developers implement protocols correctly. A simple design (see 2.1) is one way to help achieve this. Providing test vectors, and other metrics to measure implementations, is another way to make secure implementation easier; this enables developers to ensure that their implementation acts as expected, and also gives users confidence that an implementation they are using is secure. Thinking about how a protocol will scale is also valuable – a design that remains robust, performant and secure is not only better for deployers but can still provide security when deployed at an unintended scale.

## 3.3 Allow use of the least privilege

Data breaches happen every day and this is not about to change. Devices and databases will be compromised, so our motivating goal to reduce the impact of compromise is crucial. The principle of least privilege is to restrict each component to only have access to the information necessary for it to perform the functions for its job. Restricting permissions appropriately is a vital part of security - maintaining user privacy while delivering rich-enough functionality.

If a protocol design means that components in a system are given greater privilege than they really need, the consequences of a compromise of one of those components are correspondingly worse than they need to be. For example, a protocol that requires constant access to cryptographic keys in turn means that a malicious actor gaining access to an endpoint running that protocol has access to those keys. This not only compromises the protocol, but any other data secured using those keys, potentially causing a massive breach of privacy. Recovering from a compromise is also much easier if least privilege is applied, by, for example, using tightly scoped or short-term credentials which can be easily revoked, as this drastically limits the window and extent of the compromise.

Applying the principle of least privilege in protocol design therefore not only lessens the impact of a breach by limiting the data an attacker has access to but can also aid recovery by limiting the scope of the compromise to recover from. By allowing privilege to be limited in this way, a breach will compromise privacy as little as possible while ensuring that a system still functions effectively.

## 3.4 Plan for failure of third parties

All internet users are dependent on third parties to ensure their security and hence maintain their privacy. Using Transport Layer Security (TLS) eventually comes down to trusting a Certificate Authority (CA), while protection from Denial-of-Service (DoS) attacks is often only provided by one of a handful of big providers. If these third parties are compromised, become unavailable, or even stop functioning as expected, then the user may be vulnerable as a result. Planning for this includes mitigations like allowing expiry or revocation of credentials, if, for example, a CA is compromised. For protocols that rely on DNS this could mean considering the usability of the protocol if the necessary DNS records are unavailable. Protocols should allow a user to, at a minimum, understand what assurances are being provided by critical third parties, but ideally should provide some mitigation for compromise of those third parties.

## 3.5 Support evolution

Like the security landscape, protocols are rarely static; their implementations will grow and diverge with time. Bugs or undefined behaviour in one implementation soon spread to others due to interoperability concerns. These undefined behaviours may well be insecure, and can be effectively impossible to patch as, rightly or wrongly, interoperability concerns often override security concerns. Ideally, interoperability versus security is not a choice that users should have to make.

The [robustness principle](https://en.wikipedia.org/wiki/Robustness_principle) is to be conservative in what you send, but liberal in what you accept. Unfortunately, this approach can encourage non-conformant implementations to survive and grow. In a world of intolerant receivers, these implementations would not be able to persist, improving the likelihood of only correct, secure implementations being used. Deployment of mechanisms such as GREASE [RFC8701](https://tools.ietf.org/html/rfc8701), a lightweight way to prevent ossification (see 2.4) and extensibility failures caused by incorrect implementations of TLS, can help drive the creation of a consistent, secure ecosystem of correct implementations.

Protocols need to evolve, and designs should support this. Including extension points, and building an ecosystem so that they are preserved, supports evolution, as does easing interoperability between different versions by building in the capacity for version or parameter negotiation. How a protocol is designed will influence its deployment, which will have a massive impact on who uses it and how it is used - which in turn affects how the protocol should evolve. Considering deployment when designing the protocol will inform decisions about how best to support evolution and allow the impacts of how it will be deployed to be made clear to users.

Consider the appropriate balance between interoperability, strictness, agility and evolution for each protocol – striking the right balance will help to ensure that the protocol operates, and continues to operate, in a healthy, secure ecosystem.
